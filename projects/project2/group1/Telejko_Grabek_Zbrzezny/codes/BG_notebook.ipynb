{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use LASSO to eliminate some of the features\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# load the data\n",
    "from pathlib import Path\n",
    "from src.settings import DATA_DIR\n",
    "\n",
    "# Read the text file into a dataframe\n",
    "X = pd.read_csv(os.path.join(DATA_DIR, 'x_train.txt'), sep=' ', header=None).to_numpy()\n",
    "y = pd.read_csv(os.path.join(DATA_DIR, 'y_train.txt'), header=None).to_numpy().T[0]\n",
    "X_test = pd.read_csv(os.path.join(DATA_DIR, 'x_test.txt'), sep=' ', header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use LASSO to extract the most important features\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# use lasso\n",
    "lasso = ElasticNetCV(cv=5)\n",
    "lasso.fit(X, y)\n",
    "# get the most important features\n",
    "lasso_important_features = np.where(lasso.coef_ != 0)[0]\n",
    "len(lasso_important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.custom_feature_selectors.manual_feature_selector import ManualFeatureSelector\n",
    "from src.experiment import Experiment\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "experiment_config = [\n",
    "     Experiment(\n",
    "        classifier=SVC,\n",
    "        classifier_config={\n",
    "            \"probability\": True,\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": lasso_important_features\n",
    "        },\n",
    "    )\n",
    "    # Experiment(\n",
    "    #     classifier=RandomForestClassifier,\n",
    "    #     classifier_config={\n",
    "    #         \"n_estimators\": 100\n",
    "    #     },\n",
    "    #     feature_selector=ManualFeatureSelector,\n",
    "    #     feature_selector_config={\n",
    "    #         \"indices\": lasso_important_features\n",
    "    #     },\n",
    "    # )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_svc_mfs_287d81 in progress...\n",
      "Using 29 features, we properly classified 115/200 clients.\n",
      "Using 29 features, we properly classified 100/200 clients.\n",
      "Using 29 features, we properly classified 115/200 clients.\n",
      "Using 29 features, we properly classified 112/200 clients.\n",
      "Using 29 features, we properly classified 116/200 clients.\n",
      "{'exp_svc_mfs_287d81': -220}\n"
     ]
    }
   ],
   "source": [
    "from src.experiment_utils import perform_experiments\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exp_rfc_mfs_77d097': [array([ 64, 155, 220, 285, 323, 335, 403, 498], dtype=int64),\n",
       "  array([ 64, 155, 220, 285, 323, 335, 403, 498], dtype=int64),\n",
       "  array([ 64, 155, 220, 285, 323, 335, 403, 498], dtype=int64),\n",
       "  array([ 64, 155, 220, 285, 323, 335, 403, 498], dtype=int64),\n",
       "  array([ 64, 155, 220, 285, 323, 335, 403, 498], dtype=int64)]}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exp_gnb_mfs_b27b05': [array([ 13,  20,  21,  24,  29,  34,  35,  47,  57,  60,  64,  66,  67,\n",
       "          75,  80,  84,  98, 105, 139, 148, 152, 155, 175, 178, 184, 191,\n",
       "         198, 199, 200, 203, 204, 206, 214, 215, 220, 225, 227, 240, 249,\n",
       "         252, 253, 266, 273, 277, 281, 285, 288, 296, 303, 306, 309, 316,\n",
       "         321, 322, 323, 324, 327, 328, 335, 339, 351, 357, 359, 360, 380,\n",
       "         403, 409, 412, 415, 445, 458, 462, 466, 470, 471, 481, 489, 495,\n",
       "         498], dtype=int64),\n",
       "  array([ 13,  20,  21,  24,  29,  34,  35,  47,  57,  60,  64,  66,  67,\n",
       "          75,  80,  84,  98, 105, 139, 148, 152, 155, 175, 178, 184, 191,\n",
       "         198, 199, 200, 203, 204, 206, 214, 215, 220, 225, 227, 240, 249,\n",
       "         252, 253, 266, 273, 277, 281, 285, 288, 296, 303, 306, 309, 316,\n",
       "         321, 322, 323, 324, 327, 328, 335, 339, 351, 357, 359, 360, 380,\n",
       "         403, 409, 412, 415, 445, 458, 462, 466, 470, 471, 481, 489, 495,\n",
       "         498], dtype=int64),\n",
       "  array([ 13,  20,  21,  24,  29,  34,  35,  47,  57,  60,  64,  66,  67,\n",
       "          75,  80,  84,  98, 105, 139, 148, 152, 155, 175, 178, 184, 191,\n",
       "         198, 199, 200, 203, 204, 206, 214, 215, 220, 225, 227, 240, 249,\n",
       "         252, 253, 266, 273, 277, 281, 285, 288, 296, 303, 306, 309, 316,\n",
       "         321, 322, 323, 324, 327, 328, 335, 339, 351, 357, 359, 360, 380,\n",
       "         403, 409, 412, 415, 445, 458, 462, 466, 470, 471, 481, 489, 495,\n",
       "         498], dtype=int64),\n",
       "  array([ 13,  20,  21,  24,  29,  34,  35,  47,  57,  60,  64,  66,  67,\n",
       "          75,  80,  84,  98, 105, 139, 148, 152, 155, 175, 178, 184, 191,\n",
       "         198, 199, 200, 203, 204, 206, 214, 215, 220, 225, 227, 240, 249,\n",
       "         252, 253, 266, 273, 277, 281, 285, 288, 296, 303, 306, 309, 316,\n",
       "         321, 322, 323, 324, 327, 328, 335, 339, 351, 357, 359, 360, 380,\n",
       "         403, 409, 412, 415, 445, 458, 462, 466, 470, 471, 481, 489, 495,\n",
       "         498], dtype=int64),\n",
       "  array([ 13,  20,  21,  24,  29,  34,  35,  47,  57,  60,  64,  66,  67,\n",
       "          75,  80,  84,  98, 105, 139, 148, 152, 155, 175, 178, 184, 191,\n",
       "         198, 199, 200, 203, 204, 206, 214, 215, 220, 225, 227, 240, 249,\n",
       "         252, 253, 266, 273, 277, 281, 285, 288, 296, 303, 306, 309, 316,\n",
       "         321, 322, 323, 324, 327, 328, 335, 339, 351, 357, 359, 360, 380,\n",
       "         403, 409, 412, 415, 445, 458, 462, 466, 470, 471, 481, 489, 495,\n",
       "         498], dtype=int64)]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'calculate_score' from 'src.experiment_utils' (c:\\Users\\barto\\OneDrive\\Dokumenty\\DS2024L\\AML\\Projects\\Project 2\\AML-2024L-Offer-Acceptance-Prediction\\src\\experiment_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperiment_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m calculate_score\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'calculate_score' from 'src.experiment_utils' (c:\\Users\\barto\\OneDrive\\Dokumenty\\DS2024L\\AML\\Projects\\Project 2\\AML-2024L-Offer-Acceptance-Prediction\\src\\experiment_utils.py)"
     ]
    }
   ],
   "source": [
    "from src.experiment_utils import calculate_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13,  20,  21,  24,  29,  34,  35,  47,  57,  60,  64,  66,  67,\n",
       "        75,  80,  84,  98, 105, 139, 148, 152, 155, 175, 178, 184, 191,\n",
       "       198, 199, 200, 203, 204, 206, 214, 215, 220, 225, 227, 240, 249,\n",
       "       252, 253, 266, 273, 277, 281, 285, 288, 296, 303, 306, 309, 316,\n",
       "       321, 322, 323, 324, 327, 328, 335, 339, 351, 357, 359, 360, 380,\n",
       "       403, 409, 412, 415, 445, 458, 462, 466, 470, 471, 481, 489, 495,\n",
       "       498], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso_important_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_svc_mfs_5e75ee in progress...\n",
      "Using 10 features, we properly classified 151/200 clients.\n",
      "Using 10 features, we properly classified 141/200 clients.\n",
      "Using 10 features, we properly classified 145/200 clients.\n",
      "Using 10 features, we properly classified 152/200 clients.\n",
      "Using 10 features, we properly classified 149/200 clients.\n",
      "{'exp_svc_mfs_5e75ee': 5380}\n"
     ]
    }
   ],
   "source": [
    "# PCA to select the most important features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(X)\n",
    "pca_important_features = np.argsort(pca.explained_variance_)[::-1][:10]\n",
    "len(pca_important_features)\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=SVC,\n",
    "        classifier_config={\n",
    "            \"probability\": True,\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": pca_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_svc_mfs_54150a in progress...\n",
      "Using 7 features, we properly classified 149/200 clients.\n",
      "Using 7 features, we properly classified 138/200 clients.\n",
      "Using 7 features, we properly classified 148/200 clients.\n",
      "Using 7 features, we properly classified 147/200 clients.\n",
      "Using 7 features, we properly classified 144/200 clients.\n",
      "{'exp_svc_mfs_54150a': 5860}\n"
     ]
    }
   ],
   "source": [
    "# PCA to select the most important features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(X)\n",
    "pca_important_features = np.argsort(pca.explained_variance_)[::-1][:7]\n",
    "len(pca_important_features)\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=SVC,\n",
    "        classifier_config={\n",
    "            \"probability\": True,\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": pca_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_svc_mfs_7b2914 in progress...\n",
      "Using 5 features, we properly classified 146/200 clients.\n",
      "Using 5 features, we properly classified 136/200 clients.\n",
      "Using 5 features, we properly classified 142/200 clients.\n",
      "Using 5 features, we properly classified 138/200 clients.\n",
      "Using 5 features, we properly classified 132/200 clients.\n",
      "{'exp_svc_mfs_7b2914': 5940}\n"
     ]
    }
   ],
   "source": [
    "# PCA to select the most important features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(X)\n",
    "pca_important_features = np.argsort(pca.explained_variance_)[::-1][:5]\n",
    "len(pca_important_features)\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=SVC,\n",
    "        classifier_config={\n",
    "            \"probability\": True,\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": pca_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_svc_mfs_36dea4 in progress...\n",
      "Using 4 features, we properly classified 142/200 clients.\n",
      "Using 4 features, we properly classified 134/200 clients.\n",
      "Using 4 features, we properly classified 133/200 clients.\n",
      "Using 4 features, we properly classified 137/200 clients.\n",
      "Using 4 features, we properly classified 127/200 clients.\n",
      "{'exp_svc_mfs_36dea4': 5930}\n"
     ]
    }
   ],
   "source": [
    "# PCA to select the most important features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(X)\n",
    "pca_important_features = np.argsort(pca.explained_variance_)[::-1][:4]\n",
    "len(pca_important_features)\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=SVC,\n",
    "        classifier_config={\n",
    "            \"probability\": True,\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": pca_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_rfc_mfs_4a3d5e in progress...\n",
      "Using 6 features, we properly classified 145/200 clients.\n",
      "Using 6 features, we properly classified 129/200 clients.\n",
      "Using 6 features, we properly classified 139/200 clients.\n",
      "Using 6 features, we properly classified 134/200 clients.\n",
      "Using 6 features, we properly classified 132/200 clients.\n",
      "{'exp_rfc_mfs_4a3d5e': 5590}\n"
     ]
    }
   ],
   "source": [
    "# PCA to select the most important features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(X)\n",
    "pca_important_features = np.argsort(pca.explained_variance_)[::-1][:6]\n",
    "len(pca_important_features)\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=RandomForestClassifier,\n",
    "        classifier_config={\n",
    "            \"n_estimators\": 100,\n",
    "            \"max_depth\": 10\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": pca_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_rfc_mfs_4a467c in progress...\n",
      "Using 6 features, we properly classified 145/200 clients.\n",
      "Using 6 features, we properly classified 126/200 clients.\n",
      "Using 6 features, we properly classified 134/200 clients.\n",
      "Using 6 features, we properly classified 136/200 clients.\n",
      "Using 6 features, we properly classified 130/200 clients.\n",
      "{'exp_rfc_mfs_4a467c': 5510}\n"
     ]
    }
   ],
   "source": [
    "# PCA to select the most important features\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(X)\n",
    "pca_important_features = np.argsort(pca.explained_variance_)[::-1][:6]\n",
    "len(pca_important_features)\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=RandomForestClassifier,\n",
    "        classifier_config={\n",
    "            \"n_estimators\": 100\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": pca_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\barto\\anaconda3\\envs\\aml_env\\Lib\\site-packages\\sklearn\\decomposition\\_fastica.py:128: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_rfc_mfs_bc244c in progress...\n",
      "Using 6 features, we properly classified 143/200 clients.\n",
      "Using 6 features, we properly classified 141/200 clients.\n",
      "Using 6 features, we properly classified 148/200 clients.\n",
      "Using 6 features, we properly classified 142/200 clients.\n",
      "Using 6 features, we properly classified 147/200 clients.\n",
      "{'exp_rfc_mfs_bc244c': 6010}\n"
     ]
    }
   ],
   "source": [
    "# ICA to select the most important features\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "ica = FastICA(n_components=100)\n",
    "ica.fit(X)\n",
    "ica_important_features = np.argsort(np.abs(ica.components_).sum(axis=0))[::-1][:6]\n",
    "len(ica_important_features)\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=RandomForestClassifier,\n",
    "        classifier_config={\n",
    "            \"n_estimators\": 100\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": ica_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\barto\\anaconda3\\envs\\aml_env\\Lib\\site-packages\\sklearn\\decomposition\\_fastica.py:128: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_rfc_mfs_7d6d1a in progress...\n",
      "Using 5 features, we properly classified 140/200 clients.\n",
      "Using 5 features, we properly classified 144/200 clients.\n",
      "Using 5 features, we properly classified 142/200 clients.\n",
      "Using 5 features, we properly classified 133/200 clients.\n",
      "Using 5 features, we properly classified 143/200 clients.\n",
      "{'exp_rfc_mfs_7d6d1a': 6020}\n"
     ]
    }
   ],
   "source": [
    "# ICA to select the most important features\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "ica = FastICA(n_components=100)\n",
    "ica.fit(X)\n",
    "ica_important_features = np.argsort(np.abs(ica.components_).sum(axis=0))[::-1][:5]\n",
    "len(ica_important_features)\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=RandomForestClassifier,\n",
    "        classifier_config={\n",
    "            \"n_estimators\": 100\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": ica_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\barto\\anaconda3\\envs\\aml_env\\Lib\\site-packages\\sklearn\\decomposition\\_fastica.py:128: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_rfc_mfs_21265a in progress...\n",
      "Using 4 features, we properly classified 134/200 clients.\n",
      "Using 4 features, we properly classified 137/200 clients.\n",
      "Using 4 features, we properly classified 128/200 clients.\n",
      "Using 4 features, we properly classified 140/200 clients.\n",
      "Using 4 features, we properly classified 136/200 clients.\n",
      "{'exp_rfc_mfs_21265a': 5950}\n"
     ]
    }
   ],
   "source": [
    "# ICA to select the most important features\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "ica = FastICA(n_components=100)\n",
    "ica.fit(X)\n",
    "ica_important_features = np.argsort(np.abs(ica.components_).sum(axis=0))[::-1][:4]\n",
    "len(ica_important_features)\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=RandomForestClassifier,\n",
    "        classifier_config={\n",
    "            \"n_estimators\": 100\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": ica_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_rfc_mfs_f74492 in progress...\n",
      "Using 2 features, we properly classified 111/200 clients.\n",
      "Using 2 features, we properly classified 107/200 clients.\n",
      "Using 2 features, we properly classified 113/200 clients.\n",
      "Using 2 features, we properly classified 115/200 clients.\n",
      "Using 2 features, we properly classified 105/200 clients.\n"
     ]
    }
   ],
   "source": [
    "# t-SNE to select the most important features\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne.fit(X)\n",
    "tsne_important_features = np.argsort(np.abs(tsne.embedding_).sum(axis=0))[::-1][:10]\n",
    "len(tsne_important_features)\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=RandomForestClassifier,\n",
    "        classifier_config={\n",
    "            \"n_estimators\": 100\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": tsne_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_rfc_mfs_ebea7b in progress...\n",
      "Using 7 features, we properly classified 150/200 clients.\n",
      "Using 7 features, we properly classified 143/200 clients.\n",
      "Using 7 features, we properly classified 141/200 clients.\n",
      "Using 7 features, we properly classified 141/200 clients.\n",
      "Using 7 features, we properly classified 151/200 clients.\n",
      "{'exp_rfc_mfs_ebea7b': 5860}\n"
     ]
    }
   ],
   "source": [
    "# use autoencoder to select the most important features\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "autoencoder = MLPRegressor(hidden_layer_sizes=(200, 100, 50, 50, 50), max_iter=1000)\n",
    "autoencoder.fit(X, X)\n",
    "autoencoder_important_features = np.argsort(np.abs(autoencoder.coefs_[0]).sum(axis=1))[::-1][:7]\n",
    "len(autoencoder_important_features)\n",
    "\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=RandomForestClassifier,\n",
    "        classifier_config={\n",
    "            \"n_estimators\": 100\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": autoencoder_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_rfc_mfs_ba9a53 in progress...\n",
      "Using 5 features, we properly classified 134/200 clients.\n",
      "Using 5 features, we properly classified 138/200 clients.\n",
      "Using 5 features, we properly classified 133/200 clients.\n",
      "Using 5 features, we properly classified 133/200 clients.\n",
      "Using 5 features, we properly classified 128/200 clients.\n",
      "{'exp_rfc_mfs_ba9a53': 5660}\n"
     ]
    }
   ],
   "source": [
    "# use autoencoder to select the most important features\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "autoencoder = MLPRegressor(hidden_layer_sizes=(200, 100, 100, 50, 50), max_iter=1000)\n",
    "autoencoder.fit(X, X)\n",
    "autoencoder_important_features = np.argsort(np.abs(autoencoder.coefs_[0]).sum(axis=1))[::-1][:5]\n",
    "len(autoencoder_important_features)\n",
    "\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=RandomForestClassifier,\n",
    "        classifier_config={\n",
    "            \"n_estimators\": 100\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": autoencoder_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_rfc_mfs_6b4f28 in progress...\n",
      "Using 6 features, we properly classified 148/200 clients.\n",
      "Using 6 features, we properly classified 147/200 clients.\n",
      "Using 6 features, we properly classified 136/200 clients.\n",
      "Using 6 features, we properly classified 134/200 clients.\n",
      "Using 6 features, we properly classified 140/200 clients.\n",
      "{'exp_rfc_mfs_6b4f28': 5850}\n"
     ]
    }
   ],
   "source": [
    "# use autoencoder to select the most important features\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "autoencoder = MLPRegressor(hidden_layer_sizes=(100, 100, 50, 50, 25), max_iter=1000)\n",
    "autoencoder.fit(X, X)\n",
    "autoencoder_important_features = np.argsort(np.abs(autoencoder.coefs_[0]).sum(axis=1))[::-1][:6]\n",
    "len(autoencoder_important_features)\n",
    "\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=RandomForestClassifier,\n",
    "        classifier_config={\n",
    "            \"n_estimators\": 100\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": autoencoder_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_rfc_mfs_12db62 in progress...\n",
      "Using 5 features, we properly classified 127/200 clients.\n",
      "Using 5 features, we properly classified 123/200 clients.\n",
      "Using 5 features, we properly classified 132/200 clients.\n",
      "Using 5 features, we properly classified 120/200 clients.\n",
      "Using 5 features, we properly classified 123/200 clients.\n",
      "{'exp_rfc_mfs_12db62': 5250}\n"
     ]
    }
   ],
   "source": [
    "# use autoencoder to select the most important features\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "autoencoder = MLPRegressor(hidden_layer_sizes=(200, 100, 100, 50, 10), max_iter=1000)\n",
    "autoencoder.fit(X, X)\n",
    "autoencoder_important_features = np.argsort(np.abs(autoencoder.coefs_[0]).sum(axis=1))[::-1][:5]\n",
    "len(autoencoder_important_features)\n",
    "\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=RandomForestClassifier,\n",
    "        classifier_config={\n",
    "            \"n_estimators\": 100\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": autoencoder_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_qda_mfs_8c2bab in progress...\n",
      "Using 7 features, we properly classified 159/200 clients.\n",
      "Using 7 features, we properly classified 152/200 clients.\n",
      "Using 7 features, we properly classified 152/200 clients.\n",
      "Using 7 features, we properly classified 155/200 clients.\n",
      "Using 7 features, we properly classified 155/200 clients.\n",
      "{'exp_qda_mfs_8c2bab': 6330}\n"
     ]
    }
   ],
   "source": [
    "# use autoencoder to select the most important features\n",
    "# and QDA for classification\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "autoencoder = MLPRegressor(hidden_layer_sizes=(200, 100, 50, 50, 50), max_iter=1000)\n",
    "autoencoder.fit(X, X)\n",
    "autoencoder_important_features = np.argsort(np.abs(autoencoder.coefs_[0]).sum(axis=1))[::-1][:7]\n",
    "len(autoencoder_important_features)\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=QuadraticDiscriminantAnalysis,\n",
    "        classifier_config={\n",
    "            \"reg_param\": 0.1\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": autoencoder_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_qda_mfs_fb5817 in progress...\n",
      "Using 5 features, we properly classified 149/200 clients.\n",
      "Using 5 features, we properly classified 151/200 clients.\n",
      "Using 5 features, we properly classified 147/200 clients.\n",
      "Using 5 features, we properly classified 148/200 clients.\n",
      "Using 5 features, we properly classified 151/200 clients.\n",
      "{'exp_qda_mfs_fb5817': 6460}\n"
     ]
    }
   ],
   "source": [
    "# use autoencoder to select the most important features\n",
    "# and QDA for classification\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "autoencoder = MLPRegressor(hidden_layer_sizes=(200, 100, 50, 50, 50), max_iter=1000)\n",
    "autoencoder.fit(X, X)\n",
    "autoencoder_important_features = np.argsort(np.abs(autoencoder.coefs_[0]).sum(axis=1))[::-1][:5]\n",
    "len(autoencoder_important_features)\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=QuadraticDiscriminantAnalysis,\n",
    "        classifier_config={\n",
    "            \"reg_param\": 0.18\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": autoencoder_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_qda_mfs_1210a2 in progress...\n",
      "Using 6 features, we properly classified 149/200 clients.\n",
      "Using 6 features, we properly classified 146/200 clients.\n",
      "Using 6 features, we properly classified 147/200 clients.\n",
      "Using 6 features, we properly classified 149/200 clients.\n",
      "Using 6 features, we properly classified 152/200 clients.\n",
      "{'exp_qda_mfs_1210a2': 6230}\n"
     ]
    }
   ],
   "source": [
    "# use autoencoder to select the most important features\n",
    "# and QDA for classification\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "autoencoder = MLPRegressor(hidden_layer_sizes=(200, 100, 50, 50, 50), max_iter=1000)\n",
    "autoencoder.fit(X, X)\n",
    "autoencoder_important_features = np.argsort(np.abs(autoencoder.coefs_[0]).sum(axis=1))[::-1][:6]\n",
    "len(autoencoder_important_features)\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=QuadraticDiscriminantAnalysis,\n",
    "        classifier_config={\n",
    "            \"reg_param\": 0.05\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": autoencoder_important_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exp_qda_mfs_1210a2': [array([100, 109, 106, 103, 102, 464], dtype=int64),\n",
       "  array([100, 109, 106, 103, 102, 464], dtype=int64),\n",
       "  array([100, 109, 106, 103, 102, 464], dtype=int64),\n",
       "  array([100, 109, 106, 103, 102, 464], dtype=int64),\n",
       "  array([100, 109, 106, 103, 102, 464], dtype=int64)]}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_qda_mfs_18217d in progress...\n",
      "Using 4 features, we properly classified 124/200 clients.\n",
      "Using 4 features, we properly classified 121/200 clients.\n",
      "Using 4 features, we properly classified 126/200 clients.\n",
      "Using 4 features, we properly classified 124/200 clients.\n",
      "Using 4 features, we properly classified 105/200 clients.\n",
      "{'exp_qda_mfs_18217d': 5200}\n"
     ]
    }
   ],
   "source": [
    "selected_features = [0, 2, 21, 27]\n",
    "\n",
    "# use autoencoder to select the most important features\n",
    "# and QDA for classification\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=QuadraticDiscriminantAnalysis,\n",
    "        classifier_config={\n",
    "            \"reg_param\": 0\n",
    "        },\n",
    "        feature_selector=ManualFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"indices\": selected_features\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Feature Selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ndarray\n",
    "from src.feature_selector import BaseFeatureSelector\n",
    "\n",
    "class MLPFeatureSelector(BaseFeatureSelector):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.model = MLPFeatureSelector(hidden_layer_sizes=(200, 100, 50, 50, 50), max_iter=1000)\n",
    "        self.top_k = 5\n",
    "        self._fitted = False\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.model.fit(X, y)\n",
    "        self._fitted = True\n",
    "    \n",
    "    def get_support(self, indices: bool = True) -> ndarray:\n",
    "        if not self._fitted:\n",
    "            raise ValueError(\"The model is not fitted\")\n",
    "        if indices:\n",
    "            return np.argsort(np.abs(self.model.coefs_[0]).sum(axis=1))[::-1][:self.top_k]\n",
    "        mask = np.zeros(self.X.shape[1], dtype=bool)\n",
    "        mask[self.get_support(indices=True)] = True\n",
    "        return mask\n",
    "\n",
    "    def transform(self, X) -> ndarray:\n",
    "        return X[:, self.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from src.feature_selector import BaseFeatureSelector\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "class CombinedFeatureSelector(BaseFeatureSelector):\n",
    "\n",
    "    def __init__(self, top_k=10, alpha=0.01, n_features_to_select=10) -> None:\n",
    "        self.top_k = top_k\n",
    "        self.alpha = alpha\n",
    "        self.n_features_to_select = n_features_to_select\n",
    "        self._fitted = False\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Step 1: Univariate feature selection (Filter method)\n",
    "        self.select_k_best = SelectKBest(score_func=f_classif, k=self.top_k)\n",
    "        self.select_k_best.fit(X, y)\n",
    "        self.k_best_indices = self.select_k_best.get_support(indices=True)\n",
    "\n",
    "        # model = KNeighborsClassifier(n_neighbors=3)\n",
    "        model = GradientBoostingClassifier()\n",
    "        # Step 2: Recursive Feature Elimination (Wrapper method)\n",
    "        self.rfe_model = RFE(estimator=model, n_features_to_select=self.n_features_to_select)\n",
    "        self.rfe_model.fit(X[:, self.k_best_indices], y)\n",
    "        self.rfe_indices = self.k_best_indices[self.rfe_model.get_support(indices=True)]\n",
    "\n",
    "        # Step 3: Lasso feature selection (Embedded method)\n",
    "        self.lasso = Lasso(alpha=self.alpha)\n",
    "        self.lasso.fit(X[:, self.rfe_indices], y)\n",
    "        self.lasso_indices = self.rfe_indices[np.abs(self.lasso.coef_) > 0]\n",
    "\n",
    "        self.selected_features_ = self.lasso_indices\n",
    "        self._fitted = True\n",
    "    \n",
    "    def get_support(self, indices: bool = True) -> np.ndarray:\n",
    "        if not self._fitted:\n",
    "            raise ValueError(\"The model is not fitted\")\n",
    "        if indices:\n",
    "            return self.selected_features_\n",
    "        mask = np.zeros(X.shape[1], dtype=bool)\n",
    "        mask[self.selected_features_] = True\n",
    "        return mask\n",
    "\n",
    "    def transform(self, X) -> np.ndarray:\n",
    "        return X[:, self.get_support()]\n",
    "\n",
    "# Example usage:\n",
    "# selector = CombinedFeatureSelector(top_k=20, alpha=0.01, n_features_to_select=10)\n",
    "# selector.fit(X_train, y_train)\n",
    "# X_train_selected = selector.transform(X_train)\n",
    "# X_test_selected = selector.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment exp_svc_cfs_b2918f in progress...\n",
      "Using 8 features, we properly classified 91/200 clients.\n",
      "Using 8 features, we properly classified 98/200 clients.\n",
      "Using 8 features, we properly classified 102/200 clients.\n",
      "Using 8 features, we properly classified 95/200 clients.\n",
      "Using 8 features, we properly classified 119/200 clients.\n",
      "{'exp_svc_cfs_b2918f': 3450}\n"
     ]
    }
   ],
   "source": [
    "# perform experiments with the combined feature selector\n",
    "from src.experiment import Experiment\n",
    "from src.experiment_utils import perform_experiments\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "experiment_config = [\n",
    "    Experiment(\n",
    "        classifier=SVC,\n",
    "        classifier_config={\n",
    "            \"probability\": True,\n",
    "        },\n",
    "        feature_selector=CombinedFeatureSelector,\n",
    "        feature_selector_config={\n",
    "            \"top_k\": 50,\n",
    "            \"alpha\": 0.003,\n",
    "            \"n_features_to_select\": 8\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "scores, indices = perform_experiments(X, y, experiment_config)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose sklearn different implementations of feature selection\n",
    "\n",
    "feature_selectors = [\n",
    "    ManualFeatureSelector,\n",
    "    PCA,\n",
    "    FastICA,\n",
    "    TSNE,\n",
    "    MLPRegressor\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
