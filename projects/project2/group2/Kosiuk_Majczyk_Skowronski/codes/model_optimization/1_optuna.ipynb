{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from utils import custom_optuna_score, task_score, task_score_cv\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import optuna \n",
    "from optuna.study import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from tqdm.notebook import tqdm  \n",
    "from sklearn.metrics import precision_score, f1_score, recall_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"../../../data/x_train.txt\", header=None, sep=\" \")\n",
    "y_train = pd.read_csv(\"../../../data/y_train.txt\", header=None, sep=\" \")\n",
    "\n",
    "df_train = pd.concat([x_train, y_train], axis=1)\n",
    "df_train.columns = [\"x\" + str(i) for i in range(1, df_train.shape[1])] + [\"y\"]\n",
    "\n",
    "\n",
    "X, y = df_train.drop(columns=\"y\"), df_train[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_best_features = {\n",
    "    \"Iterative\":\n",
    "    [['x103', 'x106', 'x101', 'x5', 'x102', 'x105'],\n",
    "    ['x103', 'x106', 'x101', 'x102', 'x105'],\n",
    "    ['x103','x106','x101','x102'],\n",
    "    ['x103','x106','x101','x105'],\n",
    "    ['x103','x106','x102','x105'],\n",
    "    ['x103','x101','x102','x105'],\n",
    "    ['x106','x101','x102','x105']],   \n",
    "    \"TreeMIF\": [\n",
    "    [\"x105\",\"x102\",\"x103\",\"x106\",\"x101\"],\n",
    "    [\"x102\",\"x103\",\"x106\", \"x101\",\"x104\"],\n",
    "    [\"x102\",\"x106\",\"x101\",\"x104\"],\n",
    "    [\"x102\",\"x103\",\"x106\",\"x101\"],\n",
    "    [\"x102\",\"x106\",\"x104\"],\n",
    "    [\"x102\",\"x103\",\"x101\",\"x104\"],\n",
    "    [\"x105\",\"x9\",\"x103\",\"x101\",\"x104\"],],\n",
    "    \"Genetic\": [\n",
    "    [\"x423\"],\n",
    "    [\"x459\"],\n",
    "    [\"x329\", \"x352\",\"x413\"],],\n",
    "    \"LassoSVC\": [\n",
    "    ['x106', 'x140', 'x153', 'x156', 'x176', 'x22', 'x221', 'x253', 'x324',\n",
    "       'x329', 'x336', 'x352', 'x36', 'x404', 'x413', 'x459', 'x499', 'x58',\n",
    "       'x65', 'x81'],],\n",
    "    \"LassoLR\": [\n",
    "    ['x1', 'x101', 'x102', 'x103', 'x104', 'x105', 'x106', 'x132', 'x140',\n",
    "       'x149', 'x153', 'x156', 'x176', 'x191', 'x22', 'x221', 'x229', 'x253',\n",
    "       'x286', 'x304', 'x322', 'x323', 'x324', 'x329', 'x336', 'x35', 'x352',\n",
    "       'x36', 'x40', 'x404', 'x413', 'x423', 'x459', 'x463', 'x499', 'x5',\n",
    "       'x58', 'x65', 'x74', 'x8', 'x81', 'x99'],],\n",
    "   \"Boruta\": [\n",
    "       [\"x101\", \"x102\", \"x103\", \"x104\", \"x105\", \"x106\", \"x9\"],\n",
    "   ],\n",
    "   \"Filters\": [[\"x106\", \"x176\", \"x413\", \"x459\"]],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "\n",
    "for feature_selection_method, features_list in tqdm(possible_best_features.items(), total=len(possible_best_features), desc=\"Feature selection method\"):\n",
    "    print(f\"Feature selection method: {feature_selection_method}\")\n",
    "    for features in tqdm(features_list, total=len(features_list), desc=\"Features\"):\n",
    "        print(f\"Features: {features}\")\n",
    "            \n",
    "        X_train_ = X[features]\n",
    "        y_train_ = y\n",
    "        \n",
    "        def objective(trial):\n",
    "            C = trial.suggest_loguniform('C', 1e-3, 1e1)\n",
    "            gamma = trial.suggest_loguniform('gamma', 1e-3, 1e1)\n",
    "            svc = SVC(C=C, gamma=gamma, kernel='rbf', probability=True)\n",
    "            pipeline = make_pipeline(StandardScaler(), svc)\n",
    "            scores = cross_val_score(pipeline, X_train_, y_train_, cv=5, scoring=make_scorer(custom_optuna_score, greater_is_better=True,needs_proba=True))\n",
    "            return scores.mean()\n",
    "        \n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=10, n_jobs=-1)\n",
    "        \n",
    "        \n",
    "        print(\"Best hyperparameters: \", study.best_params,)\n",
    "        final_model = SVC(**study.best_params, probability=True)\n",
    "        final_pipeline = make_pipeline(StandardScaler(), final_model)\n",
    "\n",
    "        for i in range(5):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_train_, y_train_, test_size=0.2, stratify=df_train[\"y\"], random_state=i\n",
    "            )\n",
    "            final_pipeline.fit(X_train, y_train)\n",
    "            score = task_score(final_pipeline, X_test, y_test)\n",
    "            print(f\"Random state: {i}, score: {score}\")\n",
    "\n",
    "            \n",
    "            precision = precision_score(y_test, final_pipeline.predict(X_test))\n",
    "            f1 = f1_score(y_test, final_pipeline.predict(X_test))\n",
    "            recall = recall_score(y_test, final_pipeline.predict(X_test))\n",
    "            accuracy = accuracy_score(y_test, final_pipeline.predict(X_test))\n",
    "\n",
    "        \n",
    "            results.append({\n",
    "                **study.best_params,\n",
    "                \"features\": \"_\".join(features),\n",
    "                \"test_score\": score,\n",
    "                \"random_state\": i,\n",
    "                \"feature_selection_method\": feature_selection_method,\n",
    "                \"precision\": precision,\n",
    "                \"f1\": f1,\n",
    "                \"recall\": recall,\n",
    "                \"accuracy\": accuracy,\n",
    "                \n",
    "\n",
    "                \n",
    "            })\n",
    "path = os.path.join(\"optuna\")\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(f\"{path}/results_svm.csv\", index=False)\n",
    "\n",
    "\n",
    "        # BEZ SENSU ZAPISYWAC MODEL, BO NA KONIEC I TAK TRZEBA ZROBIC FIT NA CALYM ZBIORZE\n",
    "        # with open(f\"{path}/svm.pkl\", \"wb\") as f:\n",
    "        #     pickle.dump(final_pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for feature_selection_method, features_list in tqdm(possible_best_features.items(), total=len(possible_best_features), desc=\"Feature selection method\"):\n",
    "    print(f\"Feature selection method: {feature_selection_method}\")\n",
    "    for features in tqdm(features_list, total=len(features_list), desc=\"Features\"):\n",
    "        print(f\"Features: {features}\")\n",
    "        \n",
    "        X_train_ = X[features]\n",
    "        y_train_ = y\n",
    "        \n",
    "        def objective(trial):\n",
    "            reg_param = trial.suggest_uniform('reg_param', 0.0, 1.0)\n",
    "            qda = QDA(reg_param=reg_param)\n",
    "            pipeline = make_pipeline(StandardScaler(), qda)\n",
    "            scores = cross_val_score(pipeline, X_train_, y_train_, cv=5, scoring=make_scorer(custom_optuna_score, greater_is_better=True,needs_proba=True))\n",
    "            return scores.mean()\n",
    "        \n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=10, n_jobs=-1)\n",
    "        \n",
    "        \n",
    "        print(\"Best hyperparameters: \", study.best_params,)\n",
    "        final_model = QDA(**study.best_params)\n",
    "        final_pipeline = make_pipeline(StandardScaler(), final_model)\n",
    "\n",
    "        for i in range(5):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_train_, y_train_, test_size=0.2, stratify=df_train[\"y\"], random_state=i\n",
    "            )\n",
    "            final_pipeline.fit(X_train, y_train)\n",
    "            score = task_score(final_pipeline, X_test, y_test)\n",
    "            print(f\"Random state: {i}, score: {score}\")\n",
    "        \n",
    "\n",
    "            precision = precision_score(y_test, final_pipeline.predict(X_test))\n",
    "            f1 = f1_score(y_test, final_pipeline.predict(X_test))\n",
    "            recall = recall_score(y_test, final_pipeline.predict(X_test))\n",
    "            accuracy = accuracy_score(y_test, final_pipeline.predict(X_test))\n",
    "\n",
    "\n",
    "            results.append({\n",
    "                **study.best_params,\n",
    "                \"features\": \"_\".join(features),\n",
    "                \"test_score\": score,\n",
    "                \"random_state\": i,\n",
    "                \"feature_selection_method\": feature_selection_method,\n",
    "                \"precision\": precision,\n",
    "                \"f1\": f1,\n",
    "                \"recall\": recall,\n",
    "                \"accuracy\": accuracy\n",
    "           \n",
    "            })\n",
    "path = os.path.join(\"optuna\")\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(f\"{path}/results_qda.csv\", index=False)\n",
    "\n",
    "\n",
    "        # BEZ SENSU ZAPISYWAC MODEL, BO NA KONIEC I TAK TRZEBA ZROBIC FIT NA CALYM ZBIORZE\n",
    "        # with open(f\"{path}/svm.pkl\", \"wb\") as f:\n",
    "        #     pickle.dump(final_pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for feature_selection_method, features_list in tqdm(possible_best_features.items(), total=len(possible_best_features), desc=\"Feature selection method\"):\n",
    "    print(f\"Feature selection method: {feature_selection_method}\")\n",
    "    for features in tqdm(features_list, total=len(features_list), desc=\"Features\"):\n",
    "        print(f\"Features: {features}\")\n",
    "        \n",
    "        X_train_ = X[features]\n",
    "        y_train_ = y\n",
    "        \n",
    "        def objective(trial):\n",
    "            max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "            n_estimators = trial.suggest_int('n_estimators', 50, 500)\n",
    "            lgbm = LGBMClassifier(max_depth=max_depth, n_estimators=n_estimators)\n",
    "            pipeline = make_pipeline(StandardScaler(), lgbm)\n",
    "            scores = cross_val_score(pipeline, X_train_, y_train_, cv=5, scoring=make_scorer(custom_optuna_score, greater_is_better=True,needs_proba=True))\n",
    "            return scores.mean()\n",
    "        \n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=10, n_jobs=-1)\n",
    "        \n",
    "        \n",
    "        print(\"Best hyperparameters: \", study.best_params,)\n",
    "        final_model = LGBMClassifier(**study.best_params)\n",
    "        final_pipeline = make_pipeline(StandardScaler(), final_model)\n",
    "\n",
    "        for i in range(5):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_train_, y_train_, test_size=0.2, stratify=df_train[\"y\"], random_state=i\n",
    "            )\n",
    "            final_pipeline.fit(X_train, y_train)\n",
    "            score = task_score(final_pipeline, X_test, y_test)\n",
    "            print(f\"Random state: {i}, score: {score}\")\n",
    "        \n",
    "\n",
    "            precision = precision_score(y_test, final_pipeline.predict(X_test))\n",
    "            f1 = f1_score(y_test, final_pipeline.predict(X_test))\n",
    "            recall = recall_score(y_test, final_pipeline.predict(X_test))\n",
    "            accuracy = accuracy_score(y_test, final_pipeline.predict(X_test))\n",
    "\n",
    "\n",
    "            results.append({\n",
    "                **study.best_params,\n",
    "                \"features\": \"_\".join(features),\n",
    "                \"test_score\": score,\n",
    "                \"random_state\": i,\n",
    "                \"feature_selection_method\": feature_selection_method,\n",
    "                \"precision\": precision,\n",
    "                \"f1\": f1,\n",
    "                \"recall\": recall,\n",
    "                \"accuracy\": accuracy\n",
    "           \n",
    "            })\n",
    "path = os.path.join(\"optuna\")\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(f\"{path}/results_lgbm.csv\", index=False)\n",
    "\n",
    "\n",
    "        # BEZ SENSU ZAPISYWAC MODEL, BO NA KONIEC I TAK TRZEBA ZROBIC FIT NA CALYM ZBIORZE\n",
    "        # with open(f\"{path}/svm.pkl\", \"wb\") as f:\n",
    "        #     pickle.dump(final_pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for feature_selection_method, features_list in tqdm(possible_best_features.items(), total=len(possible_best_features), desc=\"Feature selection method\"):\n",
    "    print(f\"Feature selection method: {feature_selection_method}\")\n",
    "    for features in tqdm(features_list, total=len(features_list), desc=\"Features\"):\n",
    "        print(f\"Features: {features}\")\n",
    "        \n",
    "        X_train_ = X[features]\n",
    "        y_train_ = y\n",
    "        \n",
    "        def objective(trial):\n",
    "            max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "            n_estimators = trial.suggest_int('n_estimators', 100, 500)\n",
    "            rf = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators)\n",
    "            pipeline = make_pipeline(StandardScaler(), rf)\n",
    "            scores = cross_val_score(pipeline, X_train_, y_train_, cv=5, scoring=make_scorer(custom_optuna_score, greater_is_better=True,needs_proba=True))\n",
    "            return scores.mean()\n",
    "        \n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=10, n_jobs=-1)\n",
    "        \n",
    "        \n",
    "        print(\"Best hyperparameters: \", study.best_params,)\n",
    "        final_model = RandomForestClassifier(**study.best_params)\n",
    "        final_pipeline = make_pipeline(StandardScaler(), final_model)\n",
    "\n",
    "        for i in range(5):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_train_, y_train_, test_size=0.2, stratify=df_train[\"y\"], random_state=i\n",
    "            )\n",
    "            final_pipeline.fit(X_train, y_train)\n",
    "            score = task_score(final_pipeline, X_test, y_test)\n",
    "            print(f\"Random state: {i}, score: {score}\")\n",
    "        \n",
    "\n",
    "            precision = precision_score(y_test, final_pipeline.predict(X_test))\n",
    "            f1 = f1_score(y_test, final_pipeline.predict(X_test))\n",
    "            recall = recall_score(y_test, final_pipeline.predict(X_test))\n",
    "            accuracy = accuracy_score(y_test, final_pipeline.predict(X_test))\n",
    "\n",
    "\n",
    "            results.append({\n",
    "                **study.best_params,\n",
    "                \"features\": \"_\".join(features),\n",
    "                \"test_score\": score,\n",
    "                \"random_state\": i,\n",
    "                \"feature_selection_method\": feature_selection_method,\n",
    "                \"precision\": precision,\n",
    "                \"f1\": f1,\n",
    "                \"recall\": recall,\n",
    "                \"accuracy\": accuracy\n",
    "           \n",
    "            })\n",
    "path = os.path.join(\"optuna\")\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(f\"{path}/results_rf.csv\", index=False)\n",
    "\n",
    "\n",
    "        # BEZ SENSU ZAPISYWAC MODEL, BO NA KONIEC I TAK TRZEBA ZROBIC FIT NA CALYM ZBIORZE\n",
    "        # with open(f\"{path}/svm.pkl\", \"wb\") as f:\n",
    "        #     pickle.dump(final_pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for feature_selection_method, features_list in tqdm(possible_best_features.items(), total=len(possible_best_features), desc=\"Feature selection method\"):\n",
    "    print(f\"Feature selection method: {feature_selection_method}\")\n",
    "    for features in tqdm(features_list, total=len(features_list), desc=\"Features\"):\n",
    "        print(f\"Features: {features}\")\n",
    "        \n",
    "        X_train_ = X[features]\n",
    "        y_train_ = y\n",
    "        \n",
    "        def objective(trial):\n",
    "            penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "            c = trial.suggest_loguniform('C', 1e-3, 1e1)\n",
    "            lr = LogisticRegression(penalty=penalty, C=c, solver='liblinear')\n",
    "            pipeline = make_pipeline(StandardScaler(), lr)\n",
    "            scores = cross_val_score(pipeline, X_train_, y_train_, cv=5, scoring=make_scorer(custom_optuna_score, greater_is_better=True,needs_proba=True))\n",
    "            return scores.mean()\n",
    "        \n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(objective, n_trials=10, n_jobs=-1)\n",
    "        \n",
    "        \n",
    "        print(\"Best hyperparameters: \", study.best_params,)\n",
    "        final_model = LogisticRegression(**study.best_params, solver='liblinear')\n",
    "        final_pipeline = make_pipeline(StandardScaler(), final_model)\n",
    "\n",
    "        for i in range(5):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_train_, y_train_, test_size=0.2, stratify=df_train[\"y\"], random_state=i\n",
    "            )\n",
    "            final_pipeline.fit(X_train, y_train)\n",
    "            score = task_score(final_pipeline, X_test, y_test)\n",
    "            print(f\"Random state: {i}, score: {score}\")\n",
    "        \n",
    "\n",
    "            precision = precision_score(y_test, final_pipeline.predict(X_test))\n",
    "            f1 = f1_score(y_test, final_pipeline.predict(X_test))\n",
    "            recall = recall_score(y_test, final_pipeline.predict(X_test))\n",
    "            accuracy = accuracy_score(y_test, final_pipeline.predict(X_test))\n",
    "\n",
    "\n",
    "            results.append({\n",
    "                **study.best_params,\n",
    "                \"features\": \"_\".join(features),\n",
    "                \"test_score\": score,\n",
    "                \"random_state\": i,\n",
    "                \"feature_selection_method\": feature_selection_method,\n",
    "                \"precision\": precision,\n",
    "                \"f1\": f1,\n",
    "                \"recall\": recall,\n",
    "                \"accuracy\": accuracy\n",
    "           \n",
    "            })\n",
    "path = os.path.join(\"optuna\")\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(f\"{path}/results_lr.csv\", index=False)\n",
    "\n",
    "\n",
    "        # BEZ SENSU ZAPISYWAC MODEL, BO NA KONIEC I TAK TRZEBA ZROBIC FIT NA CALYM ZBIORZE\n",
    "        # with open(f\"{path}/svm.pkl\", \"wb\") as f:\n",
    "        #     pickle.dump(final_pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
