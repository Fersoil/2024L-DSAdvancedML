{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('../../../data/x_train.txt', header=None, sep=' ')\n",
    "y_train = pd.read_csv('../../../data/y_train.txt', header=None, sep=' ')\n",
    "df_train = pd.concat([x_train, y_train], axis=1)\n",
    "df_train.columns = [ 'x'+str(i) for i in range(1, df_train.shape[1]) ] + ['y']    \n",
    "\n",
    "initial_features =  ['x1', 'x10', 'x101', 'x102', 'x103', 'x104', 'x105', 'x106', 'x132', 'x140', 'x149', 'x153', 'x156', 'x176', 'x191', 'x2', 'x22', 'x221', 'x229', 'x253', 'x286', 'x3', 'x304', 'x322', 'x323', 'x324', 'x329', 'x336', 'x35', 'x352', 'x36', 'x4', 'x40', 'x404', 'x413', 'x423', 'x459', 'x463', 'x499', 'x5', 'x58', 'x6', 'x65', 'x7', 'x74', 'x8', 'x81', 'x9', 'x99']\n",
    "\n",
    "df_train = df_train[initial_features + ['y']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x106', 'x149', 'x153', 'x156', 'x176', 'x22', 'x221', 'x253', 'x286', 'x304', 'x322', 'x324', 'x329', 'x336', 'x352', 'x36', 'x404', 'x413', 'x459', 'x499', 'x58', 'x65', 'x81', 'x99']\n"
     ]
    }
   ],
   "source": [
    "# count correlation with y\n",
    "correlation = df_train.corr()['y'].sort_values(ascending=False)\n",
    "\n",
    "selected_features = abs(correlation).sort_values(ascending=False).index.tolist()\n",
    "selected_features.remove('y')\n",
    "\n",
    "# get top 50% features\n",
    "selected_features = selected_features[:int(len(df_train.drop(columns=['y']).columns)//2)]\n",
    "\n",
    "selected_features_corr = [f for f in selected_features if f != 'y']\n",
    "\n",
    "print(sorted(selected_features_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x1', 'x101', 'x102', 'x103', 'x104', 'x106', 'x132', 'x176', 'x191', 'x322', 'x324', 'x329', 'x336', 'x35', 'x352', 'x4', 'x40', 'x413', 'x459', 'x463', 'x5', 'x6', 'x7', 'x9']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "\n",
    "X = df_train.drop('y', axis=1)\n",
    "y = df_train['y']\n",
    "\n",
    "selector = SelectKBest(mutual_info_classif, k=int(len(df_train.drop(columns=['y']).columns)//2))\n",
    "selector.fit(X, y)\n",
    "\n",
    "selected_features_mi = X.columns[selector.get_support()].tolist()\n",
    "\n",
    "print(sorted(selected_features_mi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x1', 'x10', 'x102', 'x104', 'x106', 'x132', 'x140', 'x149', 'x156', 'x176', 'x2', 'x22', 'x3', 'x4', 'x404', 'x413', 'x423', 'x459', 'x463', 'x499', 'x5', 'x6', 'x65', 'x7', 'x8', 'x81', 'x9', 'x99']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "X = df_train.drop('y', axis=1)\n",
    "y = df_train['y']\n",
    "\n",
    "selector = VarianceThreshold(threshold=1)\n",
    "X_variance = selector.fit_transform(X)\n",
    "\n",
    "selected_features_variance = X.columns[selector.get_support()].tolist()\n",
    "\n",
    "print(sorted(selected_features_variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x106', 'x176', 'x413', 'x459']\n"
     ]
    }
   ],
   "source": [
    "intersection = set(selected_features_corr) & set(selected_features_mi) & set(selected_features_variance)\n",
    "print(sorted(intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save selected features\n",
    "selected_features = sorted(intersection)\n",
    "selected_features = {\n",
    "    'selected_features': selected_features,\n",
    "    'method': f'intersection of top 50% correlation, 50% top mutual information and variance threshold {1}'\n",
    "}\n",
    "\n",
    "# save to json\n",
    "import json\n",
    "\n",
    "with open('results/4_filters_selected_features.json', 'w') as f:\n",
    "    json.dump(selected_features, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
