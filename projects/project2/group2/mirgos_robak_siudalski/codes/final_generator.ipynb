{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0 -2.619773 -2.619533 -1.199350 -1.083335 -1.000910 -0.366967 -2.164037   \n",
      "1 -1.415579 -1.782544 -2.880270 -1.958863  1.159968  0.273030 -1.628728   \n",
      "2 -2.745092 -1.382945 -1.626015 -1.282560 -0.663146  0.052349 -2.403322   \n",
      "3  0.618998  0.455364 -0.115081  0.649040 -0.862207  2.308504  0.526114   \n",
      "4 -0.070694 -0.550509 -0.565556 -0.693065 -0.573089 -0.395862  0.003170   \n",
      "\n",
      "        7         8         9    ...        490        491        492  \\\n",
      "0 -1.210001 -0.658311 -1.489539  ...  10.849925  10.343346  10.717519   \n",
      "1 -0.175813 -0.916857 -0.570166  ...  11.489417   5.195818   3.494627   \n",
      "2 -0.765073 -0.394354 -0.806624  ...  13.934934   9.267515   4.705604   \n",
      "3 -1.094852  1.088656 -0.481210  ...  12.021328   3.852231  11.059702   \n",
      "4 -0.981609 -0.505775 -0.758430  ...   7.537788  11.229665  11.318915   \n",
      "\n",
      "        493        494        495        496        497        498        499  \n",
      "0  7.709295   5.894554  12.416573   6.765269  16.243907   7.209524   8.082021  \n",
      "1  5.529154  10.517576  15.697333  11.324938  12.187670  12.283861   5.032285  \n",
      "2  6.642557  14.658934   8.130767   7.194487  11.939354  11.653620   5.942778  \n",
      "3  7.527268   7.253120   9.791136   6.089743  10.752796   5.778888  10.366363  \n",
      "4  6.622256  12.557882   5.520360   5.397359  13.152269  10.684779   9.816471  \n",
      "\n",
      "[5 rows x 500 columns]\n",
      "\n",
      "y:\n",
      "   0\n",
      "0  0\n",
      "1  0\n",
      "2  1\n",
      "3  1\n",
      "4  1\n",
      "x:\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0  4.614910  3.533239  1.411254  1.928403  1.422256  1.684378  4.224090   \n",
      "1 -0.169494 -0.855981  1.298991  0.351354  0.076671  1.865869 -0.129600   \n",
      "2  2.444993  1.659628  1.232445  1.121979  1.202193  1.683490  1.857638   \n",
      "3  0.588978 -1.141823  1.415624 -1.170370 -0.168715 -1.056512 -0.008172   \n",
      "4 -1.178631  0.273273  0.486322  2.193375  0.486168  1.052559 -1.034791   \n",
      "\n",
      "        7         8         9    ...        490        491        492  \\\n",
      "0  1.836643  1.113460  1.939384  ...  17.571403  12.539209  10.277104   \n",
      "1  1.308967  1.067060 -1.854199  ...   9.802786  12.230521  14.895335   \n",
      "2  2.039331  1.144583 -0.094331  ...  10.570174   1.451766  16.452995   \n",
      "3 -0.044626 -0.972869 -1.989544  ...   7.797473   9.931698   3.904975   \n",
      "4  1.051397  1.885784  0.795154  ...   5.498196   4.896865  12.892968   \n",
      "\n",
      "         493       494        495        496        497       498        499  \n",
      "0  11.655283  3.832188  12.160098  13.394882   6.672058  4.921887  22.506197  \n",
      "1   5.429700  7.548378   2.895408   7.964216   8.052888  9.861593   5.841048  \n",
      "2  10.242988  3.719581   4.879446  10.613660   6.040261  4.856464   1.471197  \n",
      "3   7.980700  6.255570   8.203613  14.295876  16.386562  9.864862  16.282600  \n",
      "4  12.053610  4.856872   2.809012   7.240177   3.184421  7.564601   4.979622  \n",
      "\n",
      "[5 rows x 500 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read x_train.txt\n",
    "X = pd.read_csv('../data/x_train.txt', sep=' ', header=None)\n",
    "\n",
    "# Read y_train.txt\n",
    "y = pd.read_csv('../data/y_train.txt', sep=' ', header=None)\n",
    "\n",
    "X_real = pd.read_csv('../data/x_test.txt', sep=' ', header=None)\n",
    "\n",
    "\n",
    "# Display the data\n",
    "print(\"x:\")\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\ny:\")\n",
    "print(y.head())\n",
    "\n",
    "# Display the data\n",
    "print(\"x:\")\n",
    "print(X_real.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generation for NM + [102, 103, 105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mgr\\aml\\pr2\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "cols=[102, 103, 105]\n",
    "Xl = X[cols]\n",
    "X_real_nb = X_real[cols]\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(Xl, y)\n",
    "\n",
    "preds_proba = model.predict_proba(X_real_nb)[:, 1]\n",
    "\n",
    "top_20_percent_indices = np.argsort(preds_proba)[-int(0.2 * len(preds_proba)):]\n",
    "#print(top_20_percent_indices)\n",
    "#print(top_20_percent_indices+1)\n",
    "# Increment each index by one\n",
    "top_20_percent_indices += 1\n",
    "\n",
    "# Save to a file\n",
    "np.savetxt(\"result-nb.txt\", top_20_percent_indices, fmt='%d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  generation for ensemble4 + [102, 103, 105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mgr\\aml\\pr2\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\mgr\\aml\\pr2\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df_e4 = pd.read_csv('ensemble4-raytune-bohb.csv')\n",
    "config_row = df_e4.loc[df_e4['custom_score'].idxmax()]\n",
    "config = {\n",
    "    \"colset\": config_row['config/colset'],\n",
    "    \"lr_C\": config_row['config/lr_C'],\n",
    "    \"lr_solver\": config_row['config/lr_solver'],\n",
    "    \"svc_C\": config_row['config/svc_C'],\n",
    "    \"svc_kernel\": config_row['config/svc_kernel'],\n",
    "    \"weight_nb\": config_row['config/weight_nb'],\n",
    "    \"weight_lr\": config_row['config/weight_lr'],\n",
    "    \"weight_svc\": config_row['config/weight_svc'],\n",
    "    \"weight_xgb\": config_row['config/weight_xgb'],\n",
    "    \"xgb_alpha\": config_row['config/xgb_alpha'],\n",
    "    \"xgb_colsample_bytree\": config_row['config/xgb_colsample_bytree'],\n",
    "    \"xgb_eta\": config_row['config/xgb_eta'],\n",
    "    \"xgb_lambda\": config_row['config/xgb_lambda'],\n",
    "    \"xgb_max_depth\": config_row['config/xgb_max_depth'],\n",
    "    \"xgb_min_child_weight\": config_row['config/xgb_min_child_weight'],\n",
    "    \"xgb_subsample\": config_row['config/xgb_subsample']\n",
    "}\n",
    "\n",
    "models = [\n",
    "        ('xgb', XGBClassifier(\n",
    "            eta=config[\"xgb_eta\"],\n",
    "            max_depth=config[\"xgb_max_depth\"],\n",
    "            min_child_weight=config[\"xgb_min_child_weight\"],\n",
    "            subsample=config[\"xgb_subsample\"],\n",
    "            colsample_bytree=config[\"xgb_colsample_bytree\"],\n",
    "            reg_lambda=config[\"xgb_lambda\"],\n",
    "            reg_alpha=config[\"xgb_alpha\"],\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"logloss\",\n",
    "            use_label_encoder=False,\n",
    "            verbosity=0\n",
    "        )),\n",
    "        ('lr', LogisticRegression(\n",
    "            C=config[\"lr_C\"],\n",
    "            solver=config[\"lr_solver\"],\n",
    "            max_iter=1000\n",
    "        )),            \n",
    "        ('svc', SVC(\n",
    "            C=config[\"svc_C\"],\n",
    "            kernel=config[\"svc_kernel\"],\n",
    "            probability=True\n",
    "        )),\n",
    "        ('nb', GaussianNB()),\n",
    "    ]\n",
    "weights = [\n",
    "    config[\"weight_xgb\"],\n",
    "    config[\"weight_lr\"],\n",
    "    config[\"weight_svc\"],\n",
    "    config[\"weight_nb\"]\n",
    "]\n",
    "model = VotingClassifier(estimators=models, voting='soft', weights=weights)\n",
    "\n",
    "vars = ast.literal_eval(config['colset'])\n",
    "Xloc = X[vars]\n",
    "X_real_e = X_real[vars]\n",
    "\n",
    "model.fit(Xloc, y)\n",
    "preds_proba = model.predict_proba(X_real_e)[:, 1]\n",
    "top_20_percent_indices = np.argsort(preds_proba)[-int(0.2 * len(preds_proba)):]\n",
    "top_20_percent_indices += 1\n",
    "np.savetxt(\"result-enseble.txt\", top_20_percent_indices, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102, 103, 105]\n"
     ]
    }
   ],
   "source": [
    "print(vars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
